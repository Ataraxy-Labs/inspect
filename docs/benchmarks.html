<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Benchmarks | inspect</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="container">
    <nav>
      <a class="logo" href="index.html">inspect</a>
      <div class="links">
        <a href="index.html">Home</a>
        <a href="benchmarks.html" class="active">Benchmarks</a>
        <a href="docs.html">Docs</a>
        <a href="changelog.html">Changelog</a>
        <a href="https://github.com/Ataraxy-Labs/inspect">GitHub</a>
        <a href="llms.txt">llms.txt</a>
      </div>
    </nav>

    <div style="padding: 48px 0 12px;">
      <h1 style="font-size: 28px; font-weight: 700; color: var(--accent); letter-spacing: -1px; margin-bottom: 12px;">Benchmarks</h1>
      <p style="font-size: 14px; color: var(--dim); line-height: 1.7; max-width: 600px;">
        inspect + LLM evaluated on the same benchmarks used to measure frontier code review tools. Entity-level triage focuses the LLM on the code that matters.
      </p>
    </div>

    <!-- AACR-Bench -->
    <section>
      <h2>AACR-Bench (Alibaba)</h2>
      <p class="section-desc">
        <a href="https://arxiv.org/abs/2601.19494" style="color:var(--cyan)">AACR-Bench</a> is the benchmark used to evaluate GPT-5.2, Claude 4.5 Sonnet, and other frontier LLMs for automated code review. 158 PRs, 1,169 ground truth issues from human reviewers, 50 open-source repos, 10 languages.
      </p>

      <h3 style="font-size: 15px; color: var(--accent); margin: 16px 0 16px;">Head-to-head: inspect vs Greptile vs CodeRabbit</h3>
      <p style="font-size: 13px; color: var(--dim); margin-bottom: 16px; line-height: 1.7;">
        We ran all tools on the same 20 AACR-Bench PRs (166 golden comments, 9 languages, 20 repos). Greptile via their production API. CodeRabbit via their CLI. inspect + LLM: triage with inspect, then review top entities per PR with an LLM. Same keyword-matching judge for all tools.
      </p>

      <div class="stat-cards">
        <div class="stat-card" style="border-color: var(--green);">
          <div class="stat-value" style="color: var(--green);">30.1%</div>
          <div class="stat-label">recall (inspect + GPT-5.2)</div>
          <div class="stat-detail">1.3x Greptile, 2.3x CodeRabbit</div>
        </div>
        <div class="stat-card" style="border-color: var(--cyan);">
          <div class="stat-value" style="color: var(--cyan);">22.7%</div>
          <div class="stat-label">precision</div>
          <div class="stat-detail">highest of all three tools</div>
        </div>
        <div class="stat-card" style="border-color: var(--purple);">
          <div class="stat-value" style="color: var(--purple);">25.9%</div>
          <div class="stat-label">F1 score</div>
          <div class="stat-detail">beats Greptile (22.5%) and CodeRabbit (23.8%)</div>
        </div>
      </div>

      <div class="comparison-table">
        <table>
          <thead>
            <tr>
              <th>Tool</th>
              <th>Recall</th>
              <th>Precision</th>
              <th>F1</th>
              <th>Findings</th>
              <th>Speed</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong style="color:var(--accent)">inspect + GPT-5.2</strong></td>
              <td class="win">30.1%</td>
              <td class="win">22.7%</td>
              <td class="win">25.9%</td>
              <td>220</td>
              <td class="win">5-15s/PR</td>
            </tr>
            <tr>
              <td>Greptile (API)</td>
              <td>23.5%</td>
              <td>21.7%</td>
              <td>22.5%</td>
              <td>180</td>
              <td>10-60s/PR</td>
            </tr>
            <tr>
              <td>CodeRabbit (CLI)</td>
              <td>13.3%</td>
              <td>115.8%*</td>
              <td>23.8%</td>
              <td>19</td>
              <td>2-5min/PR</td>
            </tr>
          </tbody>
        </table>
        <p style="font-size:11px;color:var(--dim2);margin-top:6px;">*CodeRabbit's precision exceeds 100% because multiple golden comments matched the same finding (19 findings caught 22 issues).</p>
      </div>

      <div class="bench-group" style="margin-top: 24px;">
        <h3>Recall comparison</h3>
        <div class="bench-row">
          <div class="bench-label">
            <span class="name"><strong style="color:var(--accent)">inspect + GPT-5.2</strong></span>
            <span class="value" style="color:var(--green)">30.1%</span>
          </div>
          <div class="bench-bar-track">
            <div class="bench-bar inspect-bar" data-width="30.1">30.1%</div>
          </div>
        </div>
        <div class="bench-row">
          <div class="bench-label">
            <span class="name">Greptile (API)</span>
            <span class="value">23.5%</span>
          </div>
          <div class="bench-bar-track">
            <div class="bench-bar other-bar" data-width="23.5">23.5%</div>
          </div>
        </div>
        <div class="bench-row">
          <div class="bench-label">
            <span class="name">CodeRabbit (CLI)</span>
            <span class="value">13.3%</span>
          </div>
          <div class="bench-bar-track">
            <div class="bench-bar dim-bar" data-width="13.3">13.3%</div>
          </div>
        </div>
        <div class="bench-note">20 PRs, 166 golden comments, same judge</div>
      </div>

      <div class="bench-group" style="margin-top: 24px;">
        <h3>Precision comparison</h3>
        <div class="bench-row">
          <div class="bench-label">
            <span class="name"><strong style="color:var(--accent)">inspect + GPT-5.2</strong></span>
            <span class="value" style="color:var(--green)">22.7%</span>
          </div>
          <div class="bench-bar-track">
            <div class="bench-bar inspect-bar" data-width="22.7">22.7%</div>
          </div>
        </div>
        <div class="bench-row">
          <div class="bench-label">
            <span class="name">Greptile (API)</span>
            <span class="value">21.7%</span>
          </div>
          <div class="bench-bar-track">
            <div class="bench-bar other-bar" data-width="21.7">21.7%</div>
          </div>
        </div>
        <div class="bench-note">precision = matches / total findings. CodeRabbit excluded (only 19 findings, precision not meaningful at that volume).</div>
      </div>

      <p style="font-size:13px;color:var(--dim);margin-top:12px;line-height:1.7;">
        <strong style="color:var(--fg)">Beats Greptile on all three metrics: recall, precision, and F1.</strong> inspect + GPT-5.2 catches 30.1% of real issues vs Greptile's 23.5% and CodeRabbit's 13.3%, with higher precision than Greptile (22.7% vs 21.7%). Per-language: C 92%, Go 57%, Java 75%, JavaScript 43%, Python 35%.
      </p>

      <p style="font-size:12px;color:var(--dim2);margin-top:8px;line-height:1.7;">
        20 diverse PRs from AACR-Bench (round-robin across repos). Recall = file + line or file + identifier match against golden comments. Precision = matches / total findings generated. All tools judged identically with keyword-matching heuristic. Greptile repos indexed on their default branch. CodeRabbit run locally with rate limit retries (free tier, ~2 reviews per 5 minutes). inspect + LLM reviews top 30 entities per PR (High/Critical/Medium first, then Low-risk for uncovered files) + 5-file gap review for diff coverage. Top 15 findings per PR by confidence. 10 concurrent LLM calls. Entity-level dedup (20-line window + identifier overlap) reduces noise. LLM non-determinism causes ~5% variance between runs.
      </p>
    </section>

    <!-- How it works -->
    <section>
      <h2>How it works</h2>
      <p class="section-desc">
        inspect runs entity-level triage locally (free, &lt;1s), then sends the top entities to an LLM for focused review. The LLM sees entity-scoped code with before/after context, not a raw diff.
      </p>

      <p style="font-size:13px;color:var(--dim);margin-top:20px;line-height:1.7;">
        <strong style="color:var(--fg)">The pipeline.</strong> Run inspect first (free, &lt;1s) to get entity risk rankings. Send top 30 entities to an LLM with before/after code + file diff. Gap-review uncovered files. Dedup and filter by confidence. Top 15 findings per PR. The triage step means the LLM sees focused code, not an entire diff.
      </p>
    </section>

    <!-- Speed -->
    <section>
      <h2>Speed</h2>
      <p class="section-desc">Entity extraction, dependency graph, change classification, risk scoring, commit untangling. All local, no API calls.</p>

      <h3 style="font-size: 15px; color: var(--accent); margin-bottom: 16px;">Single commit review</h3>
      <p style="font-size: 13px; color: var(--dim); margin-bottom: 16px; line-height: 1.7;">
        Time to run <code style="background:var(--surface);padding:2px 6px;border-radius:3px;font-size:12px;color:var(--cyan)">inspect diff HEAD~1</code> on a real commit. 30 runs via hyperfine, warm cache.
      </p>

      <div class="comparison-table">
        <table>
          <thead>
            <tr>
              <th>Repo</th>
              <th>Size</th>
              <th>Time</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>sem</td>
              <td>25 files, 65 entities changed</td>
              <td class="win">6ms</td>
            </tr>
            <tr>
              <td>weave</td>
              <td>80 files, 89 entities changed</td>
              <td class="win">6ms</td>
            </tr>
            <tr>
              <td>inspect</td>
              <td>50 files, large commit</td>
              <td class="win">67ms</td>
            </tr>
          </tbody>
        </table>
      </div>

      <h3 style="font-size: 15px; color: var(--accent); margin: 24px 0 16px;">Full repo history (inspect bench)</h3>
      <p style="font-size: 13px; color: var(--dim); margin-bottom: 16px; line-height: 1.7;">
        Time to analyze every commit in a repo's history: extract entities, build graph, classify changes, score risk, untangle.
      </p>

      <div class="comparison-table">
        <table>
          <thead>
            <tr>
              <th>Repo</th>
              <th>Commits</th>
              <th>Entities</th>
              <th>Wall time</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>sem</td>
              <td>38</td>
              <td>5,216</td>
              <td class="win">0.57s</td>
            </tr>
            <tr>
              <td>weave</td>
              <td>45</td>
              <td>2,854</td>
              <td class="win">1.33s</td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="bench-group" style="margin-top: 32px;">
        <h3>Single commit review time (visual)</h3>
        <div class="bench-row">
          <div class="bench-label"><span class="name">sem (25 files)</span><span class="value" style="color:var(--green)">6ms</span></div>
          <div class="bench-bar-track"><div class="bench-bar inspect-bar" data-width="9">6ms</div></div>
        </div>
        <div class="bench-row">
          <div class="bench-label"><span class="name">weave (80 files)</span><span class="value" style="color:var(--green)">6ms</span></div>
          <div class="bench-bar-track"><div class="bench-bar inspect-bar" data-width="9">6ms</div></div>
        </div>
        <div class="bench-row">
          <div class="bench-label"><span class="name">inspect (50 files)</span><span class="value" style="color:var(--green)">67ms</span></div>
          <div class="bench-bar-track"><div class="bench-bar inspect-bar" data-width="100">67ms</div></div>
        </div>
        <div class="bench-note">30 runs via hyperfine -N, warm cache</div>
      </div>

      <p style="font-size:13px;color:var(--dim);margin-top:20px;line-height:1.7;">
        Powered by <a href="https://ataraxy-labs.com/sem" style="color:var(--cyan)">sem-core</a> v0.3.0: xxHash64 structural hashing, parallel tree-sitter parsing via rayon, cached git tree resolution, LTO-optimized release builds.
      </p>
    </section>

    <footer>
      <p>Built by <a href="https://ataraxy-labs.com">Ataraxy Labs</a></p>
    </footer>
  </div>
  <script>
    // Animate bars when they scroll into view
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          const bars = entry.target.querySelectorAll('.bench-bar[data-width]');
          bars.forEach((bar, i) => {
            setTimeout(() => {
              bar.style.width = bar.dataset.width + '%';
            }, i * 80);
          });
          observer.unobserve(entry.target);
        }
      });
    }, { threshold: 0.2 });

    document.querySelectorAll('.bench-group').forEach(group => {
      observer.observe(group);
    });
  </script>
</body>
</html>
